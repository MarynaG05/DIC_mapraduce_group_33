{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c54a1b5d-7884-443b-a662-13d9cb29e9c4",
   "metadata": {},
   "source": [
    "# DIC SS 2023 - Exercise 1\n",
    "\n",
    "\n",
    "## Introduction\n",
    "Goal: Calculate Chi square measure for the top 75 items taken from the file:\n",
    "\n",
    "'reviews_devset.json' which represents a small fraction of the large file 'reviewscombined.json' which contains a set of items reviews taken from AMAZON.\n",
    "\n",
    "\n",
    "\n",
    "The computation of $\\chi ^2 _{tc}$ square is given by the formula:\n",
    "\n",
    "$ \\chi ^2 _{tc} = \\frac{N(AD-BC) ^2}{(A+B)(A+C)(B+D)(C+D)}$\n",
    "\n",
    "where:\n",
    "\n",
    "- A = number of items of category $c$ which contains the term $t$\n",
    "\n",
    "- B = number of items not of category $c$ which contain the term $t$ \n",
    "\n",
    "- C = numer of items of category $c$ which do not contain the term $t$\n",
    "\n",
    "- D = numer of items not of category $c$ which do not contain the term $t$ \n",
    "\n",
    "- N = total number of items (i.e. total number of reviews)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f110ad-0cb4-4145-bbb2-793ec1e3c803",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Here an extract of the file \"reviews_devset.json\"\n",
    "\n",
    "The only keys that are useful are \"category\" and \"reviewText\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1895fecf-3205-46e6-b766-7aaf54b02176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file = 'reviews_devset.json'\n",
    "\n",
    "f = open(file)\n",
    "\n",
    "# Since the json is not stored properly as a dictionary, must use list comprehension ...\n",
    "data = [json.loads(line)\n",
    "        for line in open(file, 'r', encoding='utf-8')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cd3e583-8f2a-49d3-b9df-321d2733d8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reviewerID': 'A2VNYWOPJ13AFP',\n",
       " 'asin': '0981850006',\n",
       " 'reviewerName': 'Amazon Customer \"carringt0n\"',\n",
       " 'helpful': [6, 7],\n",
       " 'reviewText': \"This was a gift for my other husband.  He's making us things from it all the time and we love the food.  Directions are simple, easy to read and interpret, and fun to make.  We all love different kinds of cuisine and Raichlen provides recipes from everywhere along the barbecue trail as he calls it. Get it and just open a page.  Have at it.  You'll love the food and it has provided us with an insight into the culture that produced it. It's all about broadening horizons.  Yum!!\",\n",
       " 'overall': 5.0,\n",
       " 'summary': 'Delish',\n",
       " 'unixReviewTime': 1259798400,\n",
       " 'reviewTime': '12 3, 2009',\n",
       " 'category': 'Patio_Lawn_and_Garde'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1782fb-9a3a-4b8f-83d5-0dc968a91d7b",
   "metadata": {},
   "source": [
    "### Working Example for word_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dba74e0-325f-4da0-b6a9-1d46a85d8536",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Working Example for word_counts applied to our json file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "c1d613fe-9706-42d1-9b1e-36d9c2d78277",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'reviews_devset.json'\n",
    "a = open(file ,'r').readlines()\n",
    "\n",
    "\n",
    "\n",
    "out = open('reduced.json','w')\n",
    "for l in a[:10000]:\n",
    "    out.write(l)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20894cab-0bb6-4b6b-a75d-b3b13f1495de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f024ef95-3371-4b8e-92a1-ed5d0ab9552b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78829"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "79671ef5-501b-4865-9662-cef6129f2790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting catcounter_jupyter.py\n"
     ]
    }
   ],
   "source": [
    "%%file catcounter_jupyter.py\n",
    "\n",
    "# Basic Word Count Map-Reduce in Python\n",
    "### \n",
    "import mrjob\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import json\n",
    "import re\n",
    "import os,sys\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Nice example\n",
    "https://medium.com/datable/beginners-guide-for-mapreduce-with-mrjob-in-python-dbd2e7dd0f86\n",
    "\"\"\"\n",
    "\n",
    "# Here we read the list of stopwords that must be ignored from the review text\n",
    "stop_words = open('stopwords.txt').readlines()\n",
    "stop_words = [w.replace('\\n', '') for w in open('stopwords.txt').readlines() ]\n",
    "#stop_words[:10]\n",
    "\n",
    "if not os.path.isdir('temp_out'):\n",
    "    os.mkdir('temp_out')\n",
    "\n",
    "\n",
    "# holding the number of reviews per category\n",
    "dic_category_counts = {}\n",
    "\n",
    "\n",
    "class CategoryCounter(MRJob):\n",
    "    def mapper(self, _, line):\n",
    "                \n",
    "        data = json.loads(line)\n",
    "\n",
    "        category = str(data['category'])\n",
    "        yield category,  1\n",
    "        \n",
    "    def reducer(self, cat, counts):\n",
    "        # sums up the values of all appearances of the term\n",
    "        yield  (cat, sum(counts))\n",
    "    \n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(mapper  = self.mapper,\n",
    "                   reducer = self.reducer)\n",
    "        ]\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    CategoryCounter.run()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "18cd651e-3673-41f5-b097-beacdbfbec82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Creating temp directory /tmp/catcounter_jupyter.federico.20230503.204125.877021\n",
      "Running step 1 of 1...\n",
      "job output is in /tmp/catcounter_jupyter.federico.20230503.204125.877021/output\n",
      "Streaming final output from /tmp/catcounter_jupyter.federico.20230503.204125.877021/output...\n",
      "Removing temp directory /tmp/catcounter_jupyter.federico.20230503.204125.877021...\n"
     ]
    }
   ],
   "source": [
    "#! python3.8 wordcount_jupyter.py reduced.json > output_jupyter.dat \n",
    "! python3.8 catcounter_jupyter.py reviews_devset.json > categories.dat \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7b1d5ac5-e4c2-4495-a101-961314f78d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cat_dict():\n",
    "    cat = open( 'categories.dat', 'r').readlines()\n",
    "    cats = [eval(l.split('\\t')[0].replace(\"'\",'')) for l in cat]\n",
    "    num = [int(l.split('\\t')[1].replace('\\n','')) for l in cat]\n",
    "    cat_dic = dict(zip(cats,num))\n",
    "    cat_dic['N'] = sum(cat_dic.values())\n",
    "    \n",
    "    return cat_dic \n",
    "\n",
    "cat_dict = load_cat_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bce1365b-95c9-4cfc-b1d5-afddecb3a4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dict = load_cat_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "09d6793b-5af7-4249-8831-76fc4654d006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Book': 22507,\n",
       " 'Home_and_Kitche': 4254,\n",
       " 'Kindle_Store': 3205,\n",
       " 'Apps_for_Android': 2638,\n",
       " 'Automotive': 1374,\n",
       " 'Baby': 916,\n",
       " 'Beauty': 2023,\n",
       " 'Movies_and_TV': 4607,\n",
       " 'Musical_Instrument': 500,\n",
       " 'Clothing_Shoes_and_Jewelry': 5749,\n",
       " 'Tools_and_Home_Improvement': 1926,\n",
       " 'Toys_and_Game': 2253,\n",
       " 'Grocery_and_Gourmet_Food': 1297,\n",
       " 'Health_and_Personal_Care': 2982,\n",
       " 'Digital_Music': 836,\n",
       " 'Electronic': 7825,\n",
       " 'CDs_and_Vinyl': 3749,\n",
       " 'Cell_Phones_and_Accessorie': 3447,\n",
       " 'Office_Product': 1243,\n",
       " 'Patio_Lawn_and_Garde': 994,\n",
       " 'Pet_Supplie': 1235,\n",
       " 'Sports_and_Outdoor': 3269,\n",
       " 'N': 78829}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "529d4206-1870-4c30-8e8e-795cf8e85bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting wordcount_jupyter.py\n"
     ]
    }
   ],
   "source": [
    "%%file wordcount_jupyter.py\n",
    "\n",
    "# Basic Word Count Map-Reduce in Python\n",
    "### \n",
    "import mrjob\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import json\n",
    "import re\n",
    "import os,sys\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Nice example\n",
    "https://medium.com/datable/beginners-guide-for-mapreduce-with-mrjob-in-python-dbd2e7dd0f86\n",
    "\"\"\"\n",
    "\n",
    "# Here we read the list of stopwords that must be ignored from the review text\n",
    "stop_words = open('stopwords.txt').readlines()\n",
    "stop_words = [w.replace('\\n', '') for w in open('stopwords.txt').readlines() ]\n",
    "#stop_words[:10]\n",
    "\n",
    "\n",
    "def load_cat_dict():\n",
    "    cat = open( 'categories.dat', 'r').readlines()\n",
    "    cats = [eval(l.split('\\t')[0].replace(\"'\",'')) for l in cat]\n",
    "    num = [int(l.split('\\t')[1].replace('\\n','')) for l in cat]\n",
    "    cat_dic = dict(zip(cats,num))\n",
    "    cat_dic['N'] = sum(cat_dic.values())\n",
    "    \n",
    "    return cat_dic \n",
    "\n",
    "cat_dict = load_cat_dict()\n",
    "\n",
    "\n",
    "class WordCounter(MRJob):\n",
    "\n",
    "    def mapper1(self, _, line):\n",
    "                \n",
    "        #N = N +1 \n",
    "        #self.dic_category_counts['N'] = self.dic_category_counts['N'] +1 \n",
    "        #self.N = self.N + 1\n",
    "        #self.dic_category_counts = dic_category_counts\n",
    "        \n",
    "        data = json.loads(line)\n",
    "\n",
    "        review = data['reviewText']\n",
    "        category = str(data['category'])\n",
    "        \n",
    "        # Updating the counts for categories\n",
    "        \n",
    "        #if category not in list(self.dic_category_counts.keys()):\n",
    "        #    self.dic_category_counts[category] = 0\n",
    "        #self.dic_category_counts[category] += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "        '''\n",
    "        if category not in dic_category_counts.keys():\n",
    "            dic_category_counts[category] = 0\n",
    "        dic_category_counts[category] += 1\n",
    "        '''\n",
    "        \n",
    "        # Unique ID\n",
    "        review_time = str(data['unixReviewTime'])\n",
    "        idd = data['reviewerID']\n",
    "        unique = review_time+idd \n",
    "        \n",
    "        ### Simplify word tokens\n",
    "        review_words_list = re.split('[^a-zA-Z<>^|]+', review)  # splitting words\n",
    "        review_words_list = [f.lower() for f in review_words_list] # lower case letters\n",
    "        review_words_list = [f for f in review_words_list if len(f) > 1 ] # lower case letters\n",
    "        \n",
    "        # Filter stop words\n",
    "        review_words_list = [str(w) for w in review_words_list if w not in stop_words ]\n",
    "        # Remove duplicated words\n",
    "        review_words_list = list(set(review_words_list))\n",
    "        for word in review_words_list:\n",
    "            #yield category, (word, 1, self.N, self.dic_category_counts[category] )                 \n",
    "            #yield category, (word, 1,  self.dic_category_counts['N'] , self.dic_category_counts[category] )\n",
    "            #yield category, (word, 1, cat_dict[category] )\n",
    "            yield category, (word, 1 )\n",
    "\n",
    "    '''\n",
    "    Output after the first mapper\n",
    "    \"Apps_for_Android\"\t[\"irrelevant\",1]\n",
    "    \"Apps_for_Android\"\t[\"developer\",2]\n",
    "    \"Apps_for_Android\"\t[\"update\",5]\n",
    "    '''\n",
    "            \n",
    "    def combiner1(self, cat, word_count):\n",
    "        #yield  (word, sum(counts) )\n",
    "        term_freq_dict = {}\n",
    "        for term, freq in word_count:\n",
    "            term_freq_dict[term] = term_freq_dict.get(term, 0) + freq\n",
    "        for term, freq in term_freq_dict.items():\n",
    "            yield cat, (term, freq)\n",
    "\n",
    "    '''\n",
    "    Output after the first combiner\n",
    "    \"Apps_for_Android\"\t[\"irrelevant\",1]\n",
    "    \"Apps_for_Android\"\t[\"developer\",2]\n",
    "    \"Apps_for_Android\"\t[\"update\",5]\n",
    "    '''\n",
    "            \n",
    "    \n",
    "    def reducer1(self, category, term_freqs):\n",
    "        term_freq_dict = {}\n",
    "        for term, freq in term_freqs:\n",
    "            term_freq_dict[term] = term_freq_dict.get(term, 0) + freq\n",
    "        yield category, term_freq_dict\n",
    "\n",
    "            \n",
    "    '''\n",
    "    Output after the first reducer\n",
    "    \"Patio_Lawn_and_Garde\"\t{\"interpret\":1,\"yum\":1,\"provided\":8,\"simple\":17,\"gift\":21,\"easy\":142,\n",
    "    '''\n",
    "   \n",
    "    \n",
    "    def mapper2(self, category, term_freqs):\n",
    "        for term, freq in term_freqs.items():\n",
    "            yield term, (category, freq)\n",
    "            \n",
    "    \n",
    "    '''\n",
    "    Output after mapper2\n",
    "    \"scripture\"\t[\"Apps_for_Android\",2]\n",
    "    \"time\"\t[\"Apps_for_Android\",162]\n",
    "    '''\n",
    "            \n",
    "\n",
    "    def combiner2(self, term, cat_freqs):\n",
    "        cat_freq_dict = {}\n",
    "        for category, freq in cat_freqs:\n",
    "            cat_freq_dict[category] = cat_freq_dict.get(category, 0) + freq\n",
    "        for category, freq in cat_freq_dict.items():\n",
    "            yield term, (category, freq)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Output after cobiner2\n",
    "    \"abc\"\t[\"Apps_for_Android\",1]\n",
    "    \"abcs\"\t[\"Apps_for_Android\",2]\n",
    "    \"abhors\"\t[\"Apps_for_Android\",1]\n",
    "    \"abilities\"\t[\"Apps_for_Android\",1]\n",
    "    \"ability\"\t[\"Apps_for_Android\",7]\n",
    "    '''\n",
    "    \n",
    "    def reducer2(self, term, cat_freqs):\n",
    "            cat_freq_dict = {}\n",
    "            for category, freq in cat_freqs:\n",
    "                cat_freq_dict[category] = freq\n",
    "            yield term, cat_freq_dict\n",
    "     \n",
    "\n",
    "    '''\n",
    "    Output after reducer 2\n",
    "    \"pizza\"\t{\"Patio_Lawn_and_Garde\":1}\n",
    "    \"pizzas\"\t{\"Patio_Lawn_and_Garde\":1}\n",
    "    \"place\"\t{\"Patio_Lawn_and_Garde\":34,\"Apps_for_Android\":7}\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    def mapper_chi(self, term, cat_freq_dicts):\n",
    "        \n",
    "        #yield term, cat_freq_dicts         \n",
    "\n",
    "        cat_total_dict = {} # dict holding the total freq of a term per category\n",
    "        # -> it looks already the same ad the cat_freq_dicts  ????\n",
    "        \n",
    "        \n",
    "        term_total = 0 # total frequency of the word summing all categories\n",
    "        \n",
    "        for category in cat_freq_dicts.keys():  # e.g. cat_freq_dicts = {\"Patio_Lawn_and_Garde\":34,\"Apps_for_Android\":7}\n",
    "            freq = cat_freq_dicts[category]\n",
    "            if category in cat_total_dict:\n",
    "                cat_total_dict[category] += freq\n",
    "            else:\n",
    "                cat_total_dict[category] = freq\n",
    "            term_total += freq\n",
    "                \n",
    "        \n",
    "        '''\n",
    "        - A = number of items of category $c$ which contains the term $t$\n",
    "        - B = number of items not of category $c$ which contain the term $t$ \n",
    "        - C = numer of items of category $c$ which do not contain the term $t$\n",
    "        - D = numer of items not of category $c$ which do not contain the term $t$ \n",
    "        - N = total number of items (i.e. total number of reviews)\n",
    "        '''\n",
    "        \n",
    "        chi_square = []\n",
    "        \n",
    "        #N = self.N # total number of reviews \n",
    "        #N = 2\n",
    "        for category in cat_freq_dicts.keys(): # e.g. cat_total_dict = {\"Patio_Lawn_and_Garde\":15,\"Apps_for_Android\":1},16]\n",
    "            N = cat_dict['N']\n",
    "            A = cat_freq_dicts[category]  # number of items of category $c$ which contains the term $t$ \n",
    "            B = sum(cat_freq_dicts.values()) - A # number of items not of category $c$ which contain the term $t$\n",
    "\n",
    "            C =  cat_dict[category]- A # missing \n",
    "            D = N - A - B - C \n",
    "                \n",
    "            # dummy values\n",
    "            #C = 2 # missing \n",
    "            #D = 2\n",
    "            #N = 99\n",
    "            chi = (N * ((A * D) - (B * C)) ** 2) / ((A + C) * (B + D) * (A + B) * (C + D))\n",
    "            #chi_square.append((term, category, chi))\n",
    "                \n",
    "            yield category, (term, chi)   # example output \"neighbors\"\t[{\"Patio_Lawn_and_Garde\":15,\"Apps_for_Android\":1},16]       \n",
    "\n",
    "        #top_chi = sorted(top_chi, key=lambda x: x[2], reverse=True)[:75]\n",
    "        \n",
    " \n",
    "    def reducer_chi(self, category, term_chi):\n",
    "        \n",
    "        \n",
    "        #top_75 = sorted(term_chi, key=lambda x: x[2], reverse=True)[:75]\n",
    "        all_chi = {}\n",
    "        terms, chis = [],[]\n",
    "        for t,c in term_chi:\n",
    "            terms.append(t)\n",
    "            chis.append(c)\n",
    "            \n",
    "        chis_s, terms_s = zip(*sorted(zip(chis, terms), reverse=True))\n",
    "        terms_s = list(terms_s)\n",
    "        chis_s = list(chis_s)\n",
    "        \n",
    "        dic = dict(zip(terms_s[:10] , chis_s[:10] ))\n",
    "        \n",
    "        yield None, (category, dic)\n",
    " \n",
    "        \n",
    "    def sorter(self, _, d_cat):\n",
    "        \n",
    "        # holding temp results\n",
    "        all_r = {}\n",
    "        for cat,dic in d_cat:\n",
    "            all_r[cat] = dic\n",
    "            \n",
    "        # output in sorted format\n",
    "        for c in sorted(all_r.keys()):\n",
    "            yield(c, all_r[c] )\n",
    "\n",
    "        \n",
    "        \n",
    "    def steps(self):\n",
    " \n",
    "        #self.N = 0\n",
    "        #self.dic_category_counts = {}\n",
    "        #self.dic_category_counts['N']= 0\n",
    "        \n",
    "        '''\n",
    "        return [\n",
    "            MRStep(mapper  = self.mapper1,\n",
    "                  ) ,\n",
    "        ]\n",
    "        '''\n",
    "    \n",
    "        \n",
    "        \n",
    "        return [\n",
    "            MRStep(mapper  = self.mapper1,\n",
    "                   combiner = self.combiner1,\n",
    "                   reducer = self.reducer1,\n",
    "                  ) ,\n",
    "\n",
    "            MRStep(mapper  = self.mapper2,\n",
    "                   combiner = self.combiner2,\n",
    "                   reducer = self.reducer2,\n",
    "                  ) ,    \n",
    "\n",
    "            MRStep(mapper  = self.mapper_chi,\n",
    "                   #combiner = self.combiner_chi,      \n",
    "                   reducer = self.reducer_chi,\n",
    "                  ) ,       \n",
    "            \n",
    "            MRStep(\n",
    "                   reducer = self.sorter,\n",
    "                  ) ,                   \n",
    "            \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    WordCounter.run()\n",
    "    #CategoryCounter.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "4514090e-baac-46c2-bd01-aee114f66bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Creating temp directory /tmp/wordcount_jupyter.federico.20230504.143404.710254\n",
      "Running step 1 of 4...\n",
      "Running step 2 of 4...\n",
      "Running step 3 of 4...\n",
      "Running step 4 of 4...\n",
      "job output is in /tmp/wordcount_jupyter.federico.20230504.143404.710254/output\n",
      "Streaming final output from /tmp/wordcount_jupyter.federico.20230504.143404.710254/output...\n",
      "Removing temp directory /tmp/wordcount_jupyter.federico.20230504.143404.710254...\n"
     ]
    }
   ],
   "source": [
    "#! python3.8 wordcount_jupyter.py reduced.json > output_jupyter.dat \n",
    "#! python3.8 wordcount_jupyter.py reviews_devset.json > reviews_devset_output.dat \n",
    "\n",
    "\n",
    "! python3.8 wordcount_jupyter.py reviews_devset.json > reviews_devset_output.dat \n",
    "#! python3.8 wordcount_jupyter.py reduced.json > PROVA.dat \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997ed035-5f8a-4555-90c2-96771f921b21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
