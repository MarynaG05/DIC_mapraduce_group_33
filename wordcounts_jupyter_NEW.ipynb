{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c54a1b5d-7884-443b-a662-13d9cb29e9c4",
   "metadata": {},
   "source": [
    "# DIC SS 2023 - Exercise 1\n",
    "\n",
    "\n",
    "## Introduction\n",
    "Goal: Calculate Chi square measure for the top 75 items taken from the file:\n",
    "\n",
    "'reviews_devset.json' which represents a small fraction of the large file 'reviewscombined.json' which contains a set of items reviews taken from AMAZON.\n",
    "\n",
    "\n",
    "\n",
    "The computation of $\\chi ^2 _{tc}$ square is given by the formula:\n",
    "\n",
    "$ \\chi ^2 _{tc} = \\frac{N(AD-BC) ^2}{(A+B)(A+C)(B+D)(C+D)}$\n",
    "\n",
    "where:\n",
    "\n",
    "- A = number of items of category $c$ which contains the term $t$\n",
    "\n",
    "- B = number of items not of category $c$ which contain the term $t$ \n",
    "\n",
    "- C = numer of items of category $c$ which do not contain the term $t$\n",
    "\n",
    "- D = numer of items not of category $c$ which do not contain the term $t$ \n",
    "\n",
    "- N = total number of items (i.e. total number of reviews)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f110ad-0cb4-4145-bbb2-793ec1e3c803",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Here an extract of the file \"reviews_devset.json\"\n",
    "\n",
    "The only keys that are useful are \"category\" and \"reviewText\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1895fecf-3205-46e6-b766-7aaf54b02176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file = 'reviews_devset.json'\n",
    "\n",
    "f = open(file)\n",
    "\n",
    "# Since the json is not stored properly as a dictionary, must use list comprehension ...\n",
    "data = [json.loads(line)\n",
    "        for line in open(file, 'r', encoding='utf-8')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cd3e583-8f2a-49d3-b9df-321d2733d8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reviewerID': 'A2VNYWOPJ13AFP',\n",
       " 'asin': '0981850006',\n",
       " 'reviewerName': 'Amazon Customer \"carringt0n\"',\n",
       " 'helpful': [6, 7],\n",
       " 'reviewText': \"This was a gift for my other husband.  He's making us things from it all the time and we love the food.  Directions are simple, easy to read and interpret, and fun to make.  We all love different kinds of cuisine and Raichlen provides recipes from everywhere along the barbecue trail as he calls it. Get it and just open a page.  Have at it.  You'll love the food and it has provided us with an insight into the culture that produced it. It's all about broadening horizons.  Yum!!\",\n",
       " 'overall': 5.0,\n",
       " 'summary': 'Delish',\n",
       " 'unixReviewTime': 1259798400,\n",
       " 'reviewTime': '12 3, 2009',\n",
       " 'category': 'Patio_Lawn_and_Garde'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1782fb-9a3a-4b8f-83d5-0dc968a91d7b",
   "metadata": {},
   "source": [
    "### Working Example for word_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dba74e0-325f-4da0-b6a9-1d46a85d8536",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Working Example for word_counts applied to our json file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1d613fe-9706-42d1-9b1e-36d9c2d78277",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'reviews_devset.json'\n",
    "a = open(file ,'r').readlines()\n",
    "out = open('reduced.json','w')\n",
    "for l in a[:2000]:\n",
    "    out.write(l)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "529d4206-1870-4c30-8e8e-795cf8e85bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting wordcount_jupyter.py\n"
     ]
    }
   ],
   "source": [
    "%%file wordcount_jupyter.py\n",
    "\n",
    "# Basic Word Count Map-Reduce in Python\n",
    "### \n",
    "import mrjob\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import json\n",
    "import re\n",
    "import os,sys\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Nice example\n",
    "https://medium.com/datable/beginners-guide-for-mapreduce-with-mrjob-in-python-dbd2e7dd0f86\n",
    "\"\"\"\n",
    "\n",
    "# Here we read the list of stopwords that must be ignored from the review text\n",
    "stop_words = open('stopwords.txt').readlines()\n",
    "\n",
    "# Here we read the list of stopwords that must be ignored from the review text\n",
    "stop_words = [w.replace('\\n', '') for w in open('stopwords.txt').readlines() ]\n",
    "#stop_words[:10]\n",
    "\n",
    "if not os.path.isdir('temp_out'):\n",
    "    os.mkdir('temp_out')\n",
    "    \n",
    "    \n",
    "class WordCounter(MRJob):\n",
    "\n",
    "    # Here we extract each line and read as json file\n",
    "    # we extract only category and review\n",
    "    # we filter stop words\n",
    "    \n",
    "    def mapper1(self, _, line):\n",
    " \n",
    "        data = json.loads(line)\n",
    "\n",
    "        review = data['reviewText']\n",
    "        category = str(data['category'])\n",
    "        \n",
    "        # unique ID\n",
    "        review_time = str(data['unixReviewTime'])\n",
    "        idd = data['reviewerID']\n",
    "        unique = review_time+idd \n",
    "        \n",
    "        ### Simplify word tokens\n",
    "        review_words_list = re.split('[^a-zA-Z<>^|]+', review)  # splitting words\n",
    "        review_words_list = [f.lower() for f in review_words_list] # lower case letters\n",
    "        review_words_list = [f for f in review_words_list if len(f) > 1 ] # lower case letters\n",
    "        \n",
    "        # filter stop words\n",
    "        review_words_list = [str(w) for w in review_words_list if w not in stop_words ]\n",
    "        # remove duplicated words\n",
    "        review_words_list = list(set(review_words_list))\n",
    "        for word in review_words_list:\n",
    "            yield category, (word, 1, )                 \n",
    "            #yield (category, 1)\n",
    "            \n",
    "\n",
    "    '''\n",
    "    Output after the first mapper\n",
    "    \"Apps_for_Android\"\t[\"irrelevant\",1]\n",
    "    \"Apps_for_Android\"\t[\"developer\",2]\n",
    "    \"Apps_for_Android\"\t[\"update\",5]\n",
    "    '''\n",
    "            \n",
    "    def combiner1(self, cat, word_count):\n",
    "        #yield  (word, sum(counts) )\n",
    "        term_freq_dict = {}\n",
    "        for term, freq in word_count:\n",
    "            term_freq_dict[term] = term_freq_dict.get(term, 0) + freq\n",
    "        for term, freq in term_freq_dict.items():\n",
    "            yield cat, (term, freq)\n",
    "\n",
    "    '''\n",
    "    Output after the first combiner\n",
    "    \"Apps_for_Android\"\t[\"irrelevant\",1]\n",
    "    \"Apps_for_Android\"\t[\"developer\",2]\n",
    "    \"Apps_for_Android\"\t[\"update\",5]\n",
    "    '''\n",
    "            \n",
    "    \n",
    "    def reducer1(self, category, term_freqs):\n",
    "        term_freq_dict = {}\n",
    "        for term, freq in term_freqs:\n",
    "            term_freq_dict[term] = term_freq_dict.get(term, 0) + freq\n",
    "        yield category, term_freq_dict\n",
    "\n",
    "            \n",
    "    '''\n",
    "    Output after the first reducer\n",
    "    \"Patio_Lawn_and_Garde\"\t{\"interpret\":1,\"yum\":1,\"provided\":8,\"simple\":17,\"gift\":21,\"easy\":142,\n",
    "    '''\n",
    "   \n",
    "    \n",
    "    def mapper2(self, category, term_freqs):\n",
    "        for term, freq in term_freqs.items():\n",
    "            yield term, (category, freq)\n",
    "            \n",
    "    \n",
    "    '''\n",
    "    Output after mapper2\n",
    "    \"scripture\"\t[\"Apps_for_Android\",2]\n",
    "    \"time\"\t[\"Apps_for_Android\",162]\n",
    "    '''\n",
    "            \n",
    "\n",
    "    def combiner2(self, term, cat_freqs):\n",
    "        cat_freq_dict = {}\n",
    "        for category, freq in cat_freqs:\n",
    "            cat_freq_dict[category] = cat_freq_dict.get(category, 0) + freq\n",
    "        for category, freq in cat_freq_dict.items():\n",
    "            yield term, (category, freq)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Output after cobiner2\n",
    "    \"abc\"\t[\"Apps_for_Android\",1]\n",
    "    \"abcs\"\t[\"Apps_for_Android\",2]\n",
    "    \"abhors\"\t[\"Apps_for_Android\",1]\n",
    "    \"abilities\"\t[\"Apps_for_Android\",1]\n",
    "    \"ability\"\t[\"Apps_for_Android\",7]\n",
    "    '''\n",
    "    \n",
    "    def reducer2(self, term, cat_freqs):\n",
    "            cat_freq_dict = {}\n",
    "            for category, freq in cat_freqs:\n",
    "                cat_freq_dict[category] = freq\n",
    "            yield term, cat_freq_dict\n",
    "     \n",
    "\n",
    "    '''\n",
    "    Output after reducer 2\n",
    "    \"pizza\"\t{\"Patio_Lawn_and_Garde\":1}\n",
    "    \"pizzas\"\t{\"Patio_Lawn_and_Garde\":1}\n",
    "    \"place\"\t{\"Patio_Lawn_and_Garde\":34,\"Apps_for_Android\":7}\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    def mapper_chi(self, term, cat_freq_dicts):\n",
    "        \n",
    "        #yield term, cat_freq_dicts         \n",
    "\n",
    "        cat_total_dict = {} # dict holding the total freq of a term per category\n",
    "        # -> it looks already the same ad the cat_freq_dicts  ????\n",
    "        \n",
    "        \n",
    "        term_total = 0 # total frequency of the word summing all categories\n",
    "        \n",
    "        for category in cat_freq_dicts.keys():  # e.g. cat_freq_dicts = {\"Patio_Lawn_and_Garde\":34,\"Apps_for_Android\":7}\n",
    "            freq = cat_freq_dicts[category]\n",
    "            if category in cat_total_dict:\n",
    "                cat_total_dict[category] += freq\n",
    "            else:\n",
    "                cat_total_dict[category] = freq\n",
    "            term_total += freq\n",
    "                \n",
    "        #yield term, cat_freq_dicts         \n",
    "        #yield term, (cat_total_dict, term_total)\n",
    "        \n",
    "\n",
    "        \n",
    "        N = sum(cat_total_dict.values())  ### I THINK THIS NUMBER IS WRONG...\n",
    "        # -> this is the total number of items for all categories i.e. term_freq\n",
    "        \n",
    "        \n",
    "        #yield term, cat_freq_dicts         \n",
    "        #yield term, (cat_total_dict, term_total, N )\n",
    "        \n",
    "        '''\n",
    "        - A = number of items of category $c$ which contains the term $t$\n",
    "\n",
    "        - B = number of items not of category $c$ which contain the term $t$ \n",
    "\n",
    "        - C = numer of items of category $c$ which do not contain the term $t$\n",
    "\n",
    "        - D = numer of items not of category $c$ which do not contain the term $t$ \n",
    "\n",
    "        - N = total number of items (i.e. total number of reviews)\n",
    "        '''\n",
    "        \n",
    "        chi_square = []\n",
    "        \n",
    "        N = 999\n",
    "        for category in cat_freq_dicts.keys(): # e.g. cat_total_dict = {\"Patio_Lawn_and_Garde\":15,\"Apps_for_Android\":1},16]\n",
    "            A = cat_freq_dicts[category]  # number of items of category $c$ which contains the term $t$ \n",
    "            B = sum(cat_freq_dicts.values()) - A # number of items not of category $c$ which contain the term $t$\n",
    "\n",
    "            C = 2 # missing \n",
    "            D = 2 # missing\n",
    "\n",
    "            chi = (N * ((A * D) - (B * C)) ** 2) / ((A + C) * (B + D) * (A + B) * (C + D))\n",
    "            #chi_square.append((term, category, chi))\n",
    "                \n",
    "            yield category, (term, chi)   # example output \"neighbors\"\t[{\"Patio_Lawn_and_Garde\":15,\"Apps_for_Android\":1},16]       \n",
    "\n",
    "        #top_chi = sorted(top_chi, key=lambda x: x[2], reverse=True)[:75]\n",
    "        \n",
    "        #yield term[0], top_chi         \n",
    "        #yield term, (cat_total_dict, term_total, chi_square, A, B  )   # example output \"neighbors\"\t[{\"Patio_Lawn_and_Garde\":15,\"Apps_for_Android\":1},16]       \n",
    "        #yield term, (cat_total_dict, chi_square )   # example output \"neighbors\"\t[{\"Patio_Lawn_and_Garde\":15,\"Apps_for_Android\":1},16]       \n",
    "        \n",
    "    def reducer_chi(self, category, term_chi):\n",
    "        \n",
    "        \n",
    "        #top_75 = sorted(term_chi, key=lambda x: x[2], reverse=True)[:75]\n",
    "        all_chi = {}\n",
    "        terms, chis = [],[]\n",
    "        for t,c in term_chi:\n",
    "            terms.append(t)\n",
    "            chis.append(c)\n",
    "            \n",
    "        chis_s, terms_s = zip(*sorted(zip(chis, terms), reverse=True))\n",
    "        terms_s = list(terms_s)\n",
    "        chis_s = list(chis_s)\n",
    "        \n",
    "        d = dict(zip(terms_s[:10] , chis_s[:10] ))\n",
    "        yield category, d\n",
    "        \n",
    "        \n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(mapper  = self.mapper1,\n",
    "                   combiner = self.combiner1,\n",
    "                   reducer = self.reducer1,\n",
    "                  ) ,\n",
    "            \n",
    "            MRStep(mapper  = self.mapper2,\n",
    "                   combiner = self.combiner2,\n",
    "                   reducer = self.reducer2,\n",
    "                  ) ,    \n",
    "            \n",
    "            MRStep(mapper  = self.mapper_chi,\n",
    "                   reducer = self.reducer_chi,\n",
    "\n",
    "                  ) ,              \n",
    "            \n",
    "        ]\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    WordCounter.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4514090e-baac-46c2-bd01-aee114f66bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Creating temp directory /tmp/wordcount_jupyter.federico.20230501.094047.285840\n",
      "Running step 1 of 3...\n",
      "Running step 2 of 3...\n",
      "Running step 3 of 3...\n",
      "job output is in /tmp/wordcount_jupyter.federico.20230501.094047.285840/output\n",
      "Streaming final output from /tmp/wordcount_jupyter.federico.20230501.094047.285840/output...\n",
      "\"Patio_Lawn_and_Garde\"\t{\"box\":482.56779661016947,\"plastic\":479.9117647058824,\"ordered\":479.9117647058824,\"yard\":479.52,\"plants\":479.52,\"garden\":479.11224489795916,\"arrived\":477.7826086956522,\"heavy\":476.79545454545456,\"seeds\":473.2105263157895,\"plant\":471.75}\n",
      "\"Apps_for_Android\"\t{\"graphics\":476.79545454545456,\"apps\":472.5,\"android\":466.2,\"downloaded\":465.05172413793105,\"addictive\":463.82142857142856,\"played\":461.0769230769231,\"challenging\":461.0769230769231,\"quot\":451.92857142857144,\"addicting\":451.92857142857144,\"entertaining\":449.55}\n",
      "Removing temp directory /tmp/wordcount_jupyter.federico.20230501.094047.285840...\n"
     ]
    }
   ],
   "source": [
    "#! python3.8 wordcount_jupyter.py reduced.json > output_jupyter.dat \n",
    "! python3.8 wordcount_jupyter.py reduced.json \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997ed035-5f8a-4555-90c2-96771f921b21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
